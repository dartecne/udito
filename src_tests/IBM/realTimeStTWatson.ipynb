{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test del StT de Watson de IBM\n",
    "\n",
    "kernel: python 3.10.12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import queue\n",
    "import pyaudio\n",
    "import wave\n",
    "#import webrtcvad\n",
    "from os.path import join, dirname\n",
    "import json\n",
    "import io\n",
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de PyAudio\n",
    "#CHUNK = 4096    #1024              # Tama√±o de cada fragmento de audio\n",
    "FORMAT = pyaudio.paInt16  # Formato de audio\n",
    "CHANNELS = 4              # Audio mono\n",
    "RATE = 16000 #11025              # Frecuencia de muestreo compatible con Whisper\n",
    "DURATION = 0.03\n",
    "BYTES_PRE_SAMPLE = 1\n",
    "CHUNK = DURATION * RATE  \n",
    "CHUNK = int(CHUNK)\n",
    "# === CONFIGURACI√ìN DE AUDIO ===\n",
    "#CHUNK = 1024                # 64ms\n",
    "FORMAT = pyaudio.paInt16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"es-ES\",\n",
      "  \"rate\": 8000,\n",
      "  \"language\": \"es-ES\",\n",
      "  \"description\": \"Large Castilian Spanish Model\",\n",
      "  \"supported_features\": {\n",
      "    \"custom_acoustic_model\": false,\n",
      "    \"custom_language_model\": true,\n",
      "    \"low_latency\": false,\n",
      "    \"speaker_labels\": true\n",
      "  },\n",
      "  \"decoder_method\": \"decode_ctc_v2_0_0\",\n",
      "  \"url\": \"https://api.eu-gb.speech-to-text.watson.cloud.ibm.com/instances/09491bf9-4163-452c-9671-35a92c0ff521/v1/models/es-ES\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "apikey = \"GcPMqCjN5je8m_Ef62KZNEm2xjnuyWaIEBtGuN-bFdvk\"\n",
    "url = \"https://api.eu-gb.speech-to-text.watson.cloud.ibm.com/instances/09491bf9-4163-452c-9671-35a92c0ff521\"\n",
    "\n",
    "API_KEY = apikey\n",
    "SERVICE_URL = url\n",
    "\n",
    "authenticator = IAMAuthenticator(apikey)\n",
    "speech_to_text = SpeechToTextV1(\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "speech_to_text.set_service_url(url)\n",
    "\n",
    "#speech_models = speech_to_text.list_models().get_result()\n",
    "#print(json.dumps(speech_models, indent=2))\n",
    "\n",
    "speech_model = speech_to_text.get_model('es-ES').get_result()\n",
    "print(json.dumps(speech_model, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para reproducir audio\n",
    "def play_audio(dev, data):\n",
    "    stream = dev.open(format=FORMAT, channels=CHANNELS, rate=RATE, output=True)\n",
    "    stream.write(data)\n",
    "    stream.stop_stream()\n",
    "    stream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def play_buffer(frames, rate=16000):\n",
    "    \"\"\"Reproduce el audio almacenado en un buffer de frames (lista de bytes).\"\"\"\n",
    "    if not frames:\n",
    "        print(\"‚ö†Ô∏è No hay audio para reproducir.\")\n",
    "        return\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=1,\n",
    "                    rate=rate,\n",
    "                    output=True)\n",
    "\n",
    "    print(\"üîà Reproduciendo utterance...\")\n",
    "    for chunk in frames:\n",
    "        stream.write(chunk)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    print(\"‚úÖ Reproducci√≥n finalizada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def frames_to_wav_bytes(frames, rate=16000):\n",
    "    buf = io.BytesIO()\n",
    "    wf = wave.open(buf, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(2)  # 16 bits\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    buf.seek(0)\n",
    "    return buf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.006\n",
    "def is_speech(data):\n",
    "    audio = np.frombuffer(data, dtype=np.int16).astype(np.float32)\n",
    "    rms_val = np.sqrt(np.mean(np.square(audio))) / 32768.0\n",
    "#    print(rms_val)\n",
    "    return rms_val > THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SpeechToTextV1Adapter' object has no attribute 'get_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# mediante WebSockets (no funciona todav√≠a)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Obtenemos el token de autenticaci√≥n temporal\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[43mspeech_to_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_token\u001b[49m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# URL del WebSocket (usando el modelo espa√±ol)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mes-ES_BroadbandModel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SpeechToTextV1Adapter' object has no attribute 'get_token'"
     ]
    }
   ],
   "source": [
    "# mediante WebSockets (no funciona todav√≠a)\n",
    "# Obtenemos el token de autenticaci√≥n temporal\n",
    "token = speech_to_text.get_token()\n",
    "\n",
    "# URL del WebSocket (usando el modelo espa√±ol)\n",
    "model = \"es-ES_BroadbandModel\"\n",
    "ws_url = f\"wss://api.eu-gb.speech-to-text.watson.cloud.ibm.com/v1/recognize?model={model}\"\n",
    "\n",
    "\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# === FUNCI√ìN DE STREAMING ===\n",
    "def stream_audio(ws):\n",
    "    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,\n",
    "                    input=True, frames_per_buffer=CHUNK)\n",
    "    print(\"üéôÔ∏è Hablando... (Ctrl+C para detener)\")\n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "            audio64 = base64.b64encode(data).decode('utf-8')\n",
    "            message = json.dumps({\"audio\": audio64, \"action\": \"continue\"})\n",
    "            ws.send(message)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë Terminando transmisi√≥n...\")\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        ws.send(json.dumps({\"action\": \"stop\"}))\n",
    "\n",
    "# === CALLBACKS DEL WEBSOCKET ===\n",
    "def on_open(ws):\n",
    "    print(\"‚úÖ Conectado al servicio de Watson STT.\")\n",
    "    # Configuraci√≥n inicial\n",
    "    init_msg = {\n",
    "        \"action\": \"start\",\n",
    "        \"content-type\": \"audio/l16;rate=16000;channels=1\",\n",
    "        \"interim_results\": True,\n",
    "        \"inactivity_timeout\": -1,  # nunca cerrar por inactividad\n",
    "        \"smart_formatting\": True,\n",
    "    }\n",
    "    ws.send(json.dumps(init_msg))\n",
    "\n",
    "    # Lanzar hilo de audio\n",
    "    threading.Thread(target=stream_audio, args=(ws,), daemon=True).start()\n",
    "\n",
    "def on_message(ws, message):\n",
    "    data = json.loads(message)\n",
    "    if \"results\" in data:\n",
    "        result = data[\"results\"][0]\n",
    "        transcript = result[\"alternatives\"][0][\"transcript\"].strip()\n",
    "        if result.get(\"final\"):\n",
    "            print(f\"üó£Ô∏è [FINAL]: {transcript}\")\n",
    "        else:\n",
    "            print(f\"üí¨ [PARCIAL]: {transcript}\", end='\\r')\n",
    "\n",
    "def on_error(ws, error):\n",
    "    print(f\"‚ùå Error: {error}\")\n",
    "\n",
    "def on_close(ws, code, msg):\n",
    "    print(\"üîí Conexi√≥n cerrada.\")\n",
    "\n",
    "# === INICIAR WEBSOCKET ===\n",
    "headers = [f\"Authorization: Bearer {token}\"]\n",
    "ws = WebSocketApp(ws_url, header=headers,\n",
    "                  on_open=on_open,\n",
    "                  on_message=on_message,\n",
    "                  on_error=on_error,\n",
    "                  on_close=on_close)\n",
    "\n",
    "ws.run_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è Grabando...\n",
      "‚úÖ Grabaci√≥n finalizada.\n",
      "üíæ Audio guardado en output.wav\n",
      "\n",
      "üó£Ô∏è Transcripci√≥n: esto es una frase de cinco segundos\n"
     ]
    }
   ],
   "source": [
    "# Lee audio durante RECORD_SECONDS y lo guarda en un ficher OUTPUT_WAV para StT\n",
    "\n",
    "RECORD_SECONDS = 5     # tiempo de grabaci√≥n\n",
    "OUTPUT_WAV = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# === ABRIR STREAM ===\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"üéôÔ∏è Grabando...\")\n",
    "\n",
    "frames = []\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"‚úÖ Grabaci√≥n finalizada.\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "# === GUARDAR EN WAV ===\n",
    "wf = wave.open(OUTPUT_WAV, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "\n",
    "print(f\"üíæ Audio guardado en {OUTPUT_WAV}\")\n",
    "\n",
    "# === ENVIAR A WATSON STT ===\n",
    "with open(OUTPUT_WAV, 'rb') as audio_file:\n",
    "    result = speech_to_text.recognize(\n",
    "        audio=audio_file,\n",
    "        content_type='audio/wav',\n",
    "        model='es-ES_Multimedia',  # puedes cambiar por 'es-ES_BroadbandModel'\n",
    "        timestamps=True,\n",
    "        word_confidence=True\n",
    "    ).get_result()\n",
    "\n",
    "# === MOSTRAR RESULTADO ===\n",
    "if 'results' in result and len(result['results']) > 0:\n",
    "    text = result['results'][0]['alternatives'][0]['transcript']\n",
    "    print(f\"\\nüó£Ô∏è Transcripci√≥n: {text.strip()}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No se detect√≥ texto.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_buffer(frames):\n",
    "    \"\"\"Env√≠a los frames acumulados al STT y devuelve la transcripci√≥n.\"\"\"\n",
    "    if not frames:\n",
    "        return None\n",
    "    if len(b''.join(frames)) % 2 != 0:\n",
    "        frames[-1] = frames[-1][:-1]\n",
    "#    audio_bytes = b''.join(frames)\n",
    "#    audio_stream = io.BytesIO(audio_bytes)\n",
    "    audio_stream = frames_to_wav_bytes(frames)\n",
    "    result = speech_to_text.recognize(\n",
    "        audio = audio_stream,\n",
    "        content_type = 'audio/wav',\n",
    "        model='es-ES_BroadbandModel',\n",
    "        smart_formatting=True\n",
    "    ).get_result()\n",
    "\n",
    "\n",
    "    if result.get('results'):\n",
    "        return result['results'][0]['alternatives'][0]['transcript'].strip()\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è Esperando voz (Ctrl+C para salir)...\n",
      "üé§ Detectada voz, grabando utterance...\n",
      "üõë Fin de utterance. Enviando a Watson...\n",
      "üó£Ô∏è Transcripci√≥n: los\n",
      "üé§ Detectada voz, grabando utterance...\n",
      "üõë Fin de utterance. Enviando a Watson...\n",
      "üó£Ô∏è Transcripci√≥n: c√≥mo que\n",
      "üé§ Detectada voz, grabando utterance...\n",
      "üõë Fin de utterance. Enviando a Watson...\n",
      "üó£Ô∏è Transcripci√≥n: en 1000\n",
      "\n",
      "üëã Finalizando...\n"
     ]
    }
   ],
   "source": [
    "# VAD con buffer dinamico\n",
    "# ==== INICIALIZACI√ìN ====\n",
    "SILENCE_LIMIT = 0.8\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"üéôÔ∏è Esperando voz (Ctrl+C para salir)...\")\n",
    "\n",
    "frames = []\n",
    "silence_counter = 0\n",
    "recording = False\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "\n",
    "        if is_speech(data):\n",
    "            if not recording:\n",
    "                print(\"üé§ Detectada voz, grabando utterance...\")\n",
    "                frames = []\n",
    "                recording = True\n",
    "                silence_counter = 0\n",
    "            frames.append(data)\n",
    "        else:\n",
    "            if recording:\n",
    "                silence_counter += CHUNK / RATE\n",
    "                if silence_counter > SILENCE_LIMIT:\n",
    "                    print(\"üõë Fin de utterance. Enviando a Watson...\")\n",
    "                    recording = False\n",
    "                    silence_counter = 0\n",
    "#                    play_buffer(frames, rate=RATE)\n",
    "                    text = recognize_buffer(frames)\n",
    "                    if text:\n",
    "                        print(f\"üó£Ô∏è Transcripci√≥n: {text}\")\n",
    "                    else:\n",
    "                        print(\"‚ö†Ô∏è No se reconoci√≥ texto.\")\n",
    "            # si no hay voz y no estamos grabando, no hacemos nada\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nüëã Finalizando...\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è Esperando voz (Ctrl+C para salir)...\n",
      "üé§ Detectada voz, grabando utterance...\n",
      "üõë Fin de utterance. Enviando a Watson...\n",
      "üíæ Audio guardado en output.wav\n",
      "üó£Ô∏è Transcripci√≥n: esto es una frase que duda en concreto para lo que tuvieron hablar\n",
      "\n",
      "üëã Finalizando...\n"
     ]
    }
   ],
   "source": [
    "#VAD con fichero\n",
    "# ==== INICIALIZACI√ìN ====\n",
    "SILENCE_LIMIT = 0.8\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"üéôÔ∏è Esperando voz (Ctrl+C para salir)...\")\n",
    "\n",
    "frames = []\n",
    "silence_counter = 0\n",
    "recording = False\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "\n",
    "        if is_speech(data):\n",
    "            if not recording:\n",
    "                print(\"üé§ Detectada voz, grabando utterance...\")\n",
    "                frames = []\n",
    "                recording = True\n",
    "                silence_counter = 0\n",
    "            frames.append(data)\n",
    "        else:\n",
    "            if recording:\n",
    "                silence_counter += CHUNK / RATE\n",
    "                if silence_counter > SILENCE_LIMIT:\n",
    "                    print(\"üõë Fin de utterance. Enviando a Watson...\")\n",
    "                    recording = False\n",
    "                    silence_counter = 0\n",
    "                    wf = wave.open(OUTPUT_WAV, 'wb')\n",
    "                    wf.setnchannels(CHANNELS)\n",
    "                    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "                    wf.setframerate(RATE)\n",
    "                    wf.writeframes(b''.join(frames))\n",
    "                    wf.close()\n",
    "\n",
    "                    print(f\"üíæ Audio guardado en {OUTPUT_WAV}\")\n",
    "#                    play_buffer(frames, rate=RATE)\n",
    "#                    play_audio()\n",
    "                    with open(OUTPUT_WAV, 'rb') as audio_file:\n",
    "                        result = speech_to_text.recognize(\n",
    "                            audio=audio_file,\n",
    "                            content_type='audio/wav',\n",
    "                            model='es-ES_Multimedia',  # puedes cambiar por 'es-ES_BroadbandModel'\n",
    "                            timestamps=True,\n",
    "                            word_confidence=True\n",
    "                        ).get_result()\n",
    "#                    text = recognize_buffer(frames)\n",
    "                    if result.get('results'):\n",
    "                        text = result['results'][0]['alternatives'][0]['transcript'].strip()\n",
    "                    else: \n",
    "                        text = None\n",
    "                    if text:\n",
    "                        print(f\"üó£Ô∏è Transcripci√≥n: {text}\")\n",
    "                    else:\n",
    "                        print(\"‚ö†Ô∏è No se reconoci√≥ texto.\")\n",
    "            # si no hay voz y no estamos grabando, no hacemos nada\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nüëã Finalizando...\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
