{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcripción de voz a texto en tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\programdata\\anaconda3\\envs\\whisper\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: sounddevice in c:\\programdata\\anaconda3\\envs\\whisper\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\programdata\\anaconda3\\envs\\whisper\\lib\\site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\envs\\whisper\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\envs\\whisper\\lib\\site-packages (1.10.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\programdata\\anaconda3\\envs\\whisper\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting webrtcvad\n",
      "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: webrtcvad\n",
      "  Building wheel for webrtcvad (setup.py): started\n",
      "  Building wheel for webrtcvad (setup.py): finished with status 'done'\n",
      "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp38-cp38-win_amd64.whl size=18759 sha256=c12b25f2d116e08dc1a6addebbdf678a4bfd31ca619009e86948b38516f65b22\n",
      "  Stored in directory: c:\\users\\inges\\appdata\\local\\pip\\cache\\wheels\\75\\e1\\fc\\01099a9fd0882ce84cc99eb51495812bb8a703461c2b0ca1cb\n",
      "Successfully built webrtcvad\n",
      "Installing collected packages: webrtcvad\n",
      "Successfully installed webrtcvad-2.0.10\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\whisper\\lib\\site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio\n",
    "!pip install sounddevice\n",
    "!pip install torch\n",
    "!pip install webrtcvad\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivos de audio disponibles:\n",
      "ID: 0, Nombre: Asignador de sonido Microsoft - Input, Entrada: 2, Salida: 0\n",
      "ID: 1, Nombre: Microphone (Realtek(R) Audio), Entrada: 2, Salida: 0\n",
      "ID: 2, Nombre: Asignador de sonido Microsoft - Output, Entrada: 0, Salida: 2\n",
      "ID: 3, Nombre: Speakers (Realtek(R) Audio), Entrada: 0, Salida: 2\n",
      "ID: 4, Nombre: Acer V246HQL (HD Audio Driver f, Entrada: 0, Salida: 2\n",
      "ID: 5, Nombre: Controlador primario de captura de sonido, Entrada: 2, Salida: 0\n",
      "ID: 6, Nombre: Microphone (Realtek(R) Audio), Entrada: 2, Salida: 0\n",
      "ID: 7, Nombre: Controlador primario de sonido, Entrada: 0, Salida: 2\n",
      "ID: 8, Nombre: Speakers (Realtek(R) Audio), Entrada: 0, Salida: 2\n",
      "ID: 9, Nombre: Acer V246HQL (HD Audio Driver for Display Audio), Entrada: 0, Salida: 2\n",
      "ID: 10, Nombre: Acer V246HQL (HD Audio Driver for Display Audio), Entrada: 0, Salida: 2\n",
      "ID: 11, Nombre: Speakers (Realtek(R) Audio), Entrada: 0, Salida: 2\n",
      "ID: 12, Nombre: Microphone (Realtek(R) Audio), Entrada: 2, Salida: 0\n",
      "ID: 13, Nombre: Input (), Entrada: 2, Salida: 0\n",
      "ID: 14, Nombre: Headphones (), Entrada: 0, Salida: 2\n",
      "ID: 15, Nombre: Headphones (), Entrada: 0, Salida: 2\n",
      "ID: 16, Nombre: Stereo Mix (Realtek HD Audio Stereo input), Entrada: 2, Salida: 0\n",
      "ID: 17, Nombre: Speakers 1 (Realtek HDA Primary output with SST), Entrada: 0, Salida: 2\n",
      "ID: 18, Nombre: Speakers 2 (Realtek HDA Primary output with SST), Entrada: 0, Salida: 2\n",
      "ID: 19, Nombre: PC Speaker (Realtek HDA Primary output with SST), Entrada: 2, Salida: 0\n",
      "ID: 20, Nombre: Microphone (Realtek HD Audio Mic input), Entrada: 2, Salida: 0\n",
      "ID: 21, Nombre: Headphones 1 (Realtek HD Audio 2nd output with SST), Entrada: 0, Salida: 2\n",
      "ID: 22, Nombre: Headphones 2 (Realtek HD Audio 2nd output with SST), Entrada: 0, Salida: 2\n",
      "ID: 23, Nombre: PC Speaker (Realtek HD Audio 2nd output with SST), Entrada: 2, Salida: 0\n",
      "ID: 24, Nombre: Acer V246HQL (ACX HD Audio Speaker), Entrada: 0, Salida: 2\n",
      "ID: 25, Nombre: Input (), Entrada: 2, Salida: 0\n",
      "ID: 26, Nombre: Headphones (), Entrada: 0, Salida: 2\n",
      "ID: 27, Nombre: Headphones (), Entrada: 0, Salida: 2\n",
      "ID: 28, Nombre: Headphones (), Entrada: 0, Salida: 2\n",
      "ID: 29, Nombre: Headphones (), Entrada: 0, Salida: 2\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import whisper\n",
    "import queue\n",
    "import pyaudio\n",
    "import wave\n",
    "import webrtcvad\n",
    "\n",
    "# Configuración de PyAudio\n",
    "#CHUNK = 4096    #1024              # Tamaño de cada fragmento de audio\n",
    "FORMAT = pyaudio.paInt16  # Formato de audio\n",
    "CHANNELS = 1              # Audio mono\n",
    "RATE = 16000 #11025              # Frecuencia de muestreo compatible con Whisper\n",
    "DURATION = 0.03\n",
    "BYTES_PRE_SAMPLE = 1\n",
    "chunk = DURATION * RATE  \n",
    "chunk = int(chunk)\n",
    "# Inicializar PyAudio\n",
    "audio = pyaudio.PyAudio()\n",
    "# Inicializar cola para audio\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "# Crear el modelo de Whisper\n",
    "model = whisper.load_model(\"base\")  # Cambiar el modelo según sea necesario\n",
    "\n",
    "# Inicializar VAD\n",
    "vad = webrtcvad.Vad()\n",
    "vad.set_mode(3)  # Nivel de sensibilidad: 0 (menos sensible) a 3 (más sensible)\n",
    "\n",
    "# Función para detectar actividad de voz\n",
    "def is_speech(data, sample_rate):\n",
    "#    print(\"checking if is speech...\")\n",
    "    return vad.is_speech(data, sample_rate)\n",
    "\n",
    "# Función para reproducir audio\n",
    "def play_audio(data):\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, output=True)\n",
    "    stream.write(data)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "# Función para capturar audio en tiempo real\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(f\"Status: {status}\")\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "print(\"Dispositivos de audio disponibles:\")\n",
    "for i in range(audio.get_device_count()):\n",
    "    info = audio.get_device_info_by_index(i)\n",
    "    print(f\"ID: {i}, Nombre: {info['name']}, Entrada: {info['maxInputChannels']}, Salida: {info['maxOutputChannels']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabando... Presiona Ctrl+C para detener.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\whisper\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción:  \n",
      "Transcripción:  \n",
      "Transcripción:  \n",
      "Transcripción:  \n",
      "Transcripción:  \n",
      "Transcripción:  \n",
      "Transcripción:  \n",
      "Transcripción:  \n",
      "Grabación detenida.\n"
     ]
    }
   ],
   "source": [
    "# Opcion 1.- Real-Time con sounddevice\n",
    "with sd.InputStream(samplerate=RATE, channels=CHANNELS, callback=audio_callback):\n",
    "    print(\"Grabando... Presiona Ctrl+C para detener.\")\n",
    "    try:\n",
    "        # Acumular audio y transcribir en tiempo real\n",
    "        while True:\n",
    "            audio_data = audio_queue.get()\n",
    "            # Convertir audio a un formato que Whisper entienda\n",
    "            audio_np = np.squeeze(audio_data)\n",
    "            result = model.transcribe(audio_np, language=\"es\")\n",
    "            print(\"Transcripción: \", result[\"text\"])\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Grabación detenida.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabando... Presiona Ctrl+C para detener.\n",
      "Transcripción:   esto es porque se queda abierto\n",
      "Transcripción:  \n",
      "Grabación detenida.\n"
     ]
    }
   ],
   "source": [
    "# Opcion 2.- Real-Time con pyaudio\n",
    "# transcripción contínua periódica\n",
    "# Abrir el stream para capturar el audio del micrófono\n",
    "stream = audio.open(format=FORMAT, \n",
    "                    channels=CHANNELS, \n",
    "                    rate=RATE, \n",
    "                    input=True, \n",
    "                    frames_per_buffer=chunk)\n",
    "print(\"Grabando... Presiona Ctrl+C para detener.\")\n",
    "\n",
    "try:\n",
    "    audio_buffer = b''  # Buffer para almacenar audio capturado\n",
    "    while True:\n",
    "        # Leer audio desde el micrófono\n",
    "        data = stream.read(chunk, exception_on_overflow=False)\n",
    "        audio_buffer += data\n",
    "\n",
    "        # Procesar el audio cada 5 segundos aproximadamente\n",
    "        if len(audio_buffer) >= RATE * 5:\n",
    "            # Convertir a formato que Whisper entienda\n",
    "            audio_np = np.frombuffer(audio_buffer, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "\n",
    "            # Transcribir el audio\n",
    "            result = model.transcribe(audio_np, language=\"es\")\n",
    "            print(\"Transcripción: \", result[\"text\"])\n",
    "\n",
    "            # Reproducir el audio capturado\n",
    "            play_audio(audio_buffer)\n",
    "\n",
    "            # Limpiar el buffer después de procesar\n",
    "            audio_buffer = b''\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Grabación detenida.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Cerrar streams y PyAudio\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperando actividad de voz... Presiona Ctrl+C para detener.\n",
      "Usuario comenzó a hablar...\n",
      "Usuario terminó de hablar.\n",
      "Transcribiendo...\n",
      "Transcripción:   esto es porque se queda abierto.\n",
      "Usuario comenzó a hablar...\n",
      "Usuario terminó de hablar.\n",
      "Transcribiendo...\n",
      "Transcripción:  \n",
      "Usuario comenzó a hablar...\n",
      "Usuario terminó de hablar.\n",
      "Transcribiendo...\n",
      "Transcripción:   me escucha\n",
      "Usuario comenzó a hablar...\n",
      "Usuario terminó de hablar.\n",
      "Transcribiendo...\n",
      "Transcripción:   Hola.\n",
      "Usuario comenzó a hablar...\n",
      "Usuario terminó de hablar.\n",
      "Transcribiendo...\n",
      "Transcripción:  \n",
      "Usuario comenzó a hablar...\n",
      "Usuario terminó de hablar.\n",
      "Transcribiendo...\n",
      "Transcripción:   Hola Robot.\n",
      "Usuario comenzó a hablar...\n",
      "Usuario terminó de hablar.\n",
      "Transcribiendo...\n",
      "Transcripción:   Hola robot.\n",
      "Usuario comenzó a hablar...\n",
      "Usuario terminó de hablar.\n",
      "Transcribiendo...\n",
      "Transcripción:   Empiezo a hablar.\n",
      "Grabación detenida.\n"
     ]
    }
   ],
   "source": [
    "# opcion 3.- transcripción mediante detección activa de voz VAD\n",
    "\n",
    "INPUT_DEVICE_ID = 1  # Cambiar según el dispositivo de entrada\n",
    "OUTPUT_DEVICE_ID = 3  # Cambiar según el dispositivo de salida\n",
    "\n",
    "# Abrir el stream para capturar el audio del micrófono\n",
    "stream = audio.open(format=FORMAT, \n",
    "                    channels=CHANNELS, \n",
    "                    rate=RATE, \n",
    "                    input=True, \n",
    "#                    output=False,\n",
    "#                    input_device_index=INPUT_DEVICE_ID,\n",
    "#                    output_device_index=OUTPUT_DEVICE_ID,\n",
    "                    frames_per_buffer=chunk)\n",
    "\n",
    "print(\"Esperando actividad de voz... Presiona Ctrl+C para detener.\")\n",
    "\n",
    "try:\n",
    "    audio_buffer = b''  # Buffer para almacenar audio capturado\n",
    "    speaking = False    # Indicador de actividad de voz\n",
    "    while True:\n",
    "        # Leer audio desde el micrófono\n",
    "        data = stream.read(chunk, exception_on_overflow=False)\n",
    "        \n",
    "        # Detectar actividad de voz\n",
    "        if is_speech(data, RATE):\n",
    "            if not speaking:\n",
    "                print(\"Usuario comenzó a hablar...\")\n",
    "                speaking = True\n",
    "            audio_buffer += data\n",
    "        else:\n",
    "            if speaking:\n",
    "                print(\"Usuario terminó de hablar.\")\n",
    "                speaking = False\n",
    "                \n",
    "                # Convertir el audio capturado a formato que Whisper entienda\n",
    "                audio_np = np.frombuffer(audio_buffer, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "                \n",
    "                # Transcribir el audio\n",
    "                print(\"Transcribiendo...\")\n",
    "                result = model.transcribe(audio_np, language=\"es\")\n",
    "                print(\"Transcripción: \", result[\"text\"])\n",
    "                \n",
    "                # Limpiar el buffer después de procesar\n",
    "                audio_buffer = b''\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Grabación detenida.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Cerrar streams y PyAudio\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
